{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit"
  },
  "interpreter": {
   "hash": "66c5ad3e4fe2006c058c4f7e9081f2a7de514f0ec125c3275fef48ae304ef2f7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE_LIMIT = 100\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from spacy.lang.en import English\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stopwords\n",
    "gnr_stp = []\n",
    "with open('./Data/stopwords/gnr.txt', encoding=\"utf8\") as f:\n",
    "        for line in f.readlines():\n",
    "            gnr_stp.append(line.strip())\n",
    "\n",
    "ar_stp = pd.read_csv('./Data/stopwords/ar.txt',sep='\\n').values.reshape(-1)\n",
    "de_stp = pd.read_csv('./Data/stopwords/de.txt',sep='\\n').values.reshape(-1)\n",
    "en_stp = pd.read_csv('./Data/stopwords/en.txt',sep='\\n').values.reshape(-1)\n",
    "fa_stp = pd.read_csv('./Data/stopwords/fa.txt',sep='\\n').values.reshape(-1)\n",
    "se_stp = pd.read_csv('./Data/stopwords/se.txt',sep='\\n').values.reshape(-1)\n",
    "tr_stp = pd.read_csv('./Data/stopwords/tr.txt',sep='\\n').values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessor\n",
    "def pre_df(sentence,stopwords):\n",
    "    stopwords = stopwords.tolist()\n",
    "    sentence = str(sentence).replace('\\n','')\n",
    "    sentence = str(sentence).replace('\\t','')\n",
    "    sentence = str(sentence).replace('\\r','')\n",
    "    for sym in gnr_stp:\n",
    "        sentence = str(sentence).replace(sym,'')\n",
    "    for stp in stopwords:\n",
    "        sentence = re.sub(r'\\b'+str(stp)+r'\\b', '', str(sentence))\n",
    "    \n",
    "    return sentence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                      txt\n",
       "39925   أفاد المكتب الوطني للسلامة الصحية للمنتجات الغ...\n",
       "33616   أعلنت غرفة التجارة والصناعة الإندونيسية بجاكرت...\n",
       "101358  الفريق الرباطي يبحث  تعويض مدافعه فضال ويجرب ل...\n",
       "29316   لقي شخص مغرب  الخميس مصرعه بعدما دهسه قطار  مس...\n",
       "42406   أكد وزير السياحة والصناعة التقليدية السيد ياسر..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>txt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>39925</th>\n      <td>أفاد المكتب الوطني للسلامة الصحية للمنتجات الغ...</td>\n    </tr>\n    <tr>\n      <th>33616</th>\n      <td>أعلنت غرفة التجارة والصناعة الإندونيسية بجاكرت...</td>\n    </tr>\n    <tr>\n      <th>101358</th>\n      <td>الفريق الرباطي يبحث  تعويض مدافعه فضال ويجرب ل...</td>\n    </tr>\n    <tr>\n      <th>29316</th>\n      <td>لقي شخص مغرب  الخميس مصرعه بعدما دهسه قطار  مس...</td>\n    </tr>\n    <tr>\n      <th>42406</th>\n      <td>أكد وزير السياحة والصناعة التقليدية السيد ياسر...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# import ar dataset\n",
    "ar_df = pd.read_csv('./Data/ar/ar.csv')\n",
    "ar_df = ar_df.sample(frac = 1)\n",
    "ar_df = ar_df[:SENTENCE_LIMIT]\n",
    "ar_df.drop(columns=['targe'],inplace=True)\n",
    "ar_df.columns = ['txt']\n",
    "ar_df.dropna(inplace=True)\n",
    "# stopwords and special characters\n",
    "ar_df['final'] = ar_df.apply(lambda x: pre_df(x['txt'],stopwords=ar_stp) ,axis=1)\n",
    "ar_df.dropna(inplace=True)\n",
    "ar_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                       txt\n",
       "1028685  Die Umstellung    Generation  Transporters   A...\n",
       "2176051  Sonst  Gisdol Stielike     Es   Südkorea besti...\n",
       "323578   Beschädigungen    Alten Oper   Geschäften   Ei...\n",
       "2469549               Wellmann Ja       Platz  Flieger saß\n",
       "1434362  Grosse Organisationen   gefährlicher  Einzeltä..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>txt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1028685</th>\n      <td>Die Umstellung    Generation  Transporters   A...</td>\n    </tr>\n    <tr>\n      <th>2176051</th>\n      <td>Sonst  Gisdol Stielike     Es   Südkorea besti...</td>\n    </tr>\n    <tr>\n      <th>323578</th>\n      <td>Beschädigungen    Alten Oper   Geschäften   Ei...</td>\n    </tr>\n    <tr>\n      <th>2469549</th>\n      <td>Wellmann Ja       Platz  Flieger saß</td>\n    </tr>\n    <tr>\n      <th>1434362</th>\n      <td>Grosse Organisationen   gefährlicher  Einzeltä...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# import de dataset\n",
    "de_df = pd.read_csv('./Data/de/de.txt',sep='\\t')\n",
    "de_df = de_df.sample(frac = 1)\n",
    "de_df = de_df[:SENTENCE_LIMIT]\n",
    "de_df.drop(columns=[\"1\"],inplace=True)\n",
    "de_df.columns = ['txt']\n",
    "# stopwords and special characters\n",
    "de_df['final'] = de_df.apply(lambda x: pre_df(x['txt'],stopwords=de_stp),axis=1) \n",
    "de_df.dropna(inplace=True)\n",
    "de_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                    txt  \\\n",
       "1122  \\n\\n“Let’s go on with the game,” the Queen sai...   \n",
       "1222                              But she was innocent.   \n",
       "3040                                 \\n\\n“Yes, to-day.”   \n",
       "2953  Mrs Todgers rises; the two Miss Pecksniffs ris...   \n",
       "2284  As we entered this city, our minds\\nwere fille...   \n",
       "\n",
       "                                                  final  \n",
       "1122  Lets     game  Queen   Alice  Alice  toomuch f...  \n",
       "1222                                     But   innocent  \n",
       "3040                                               Yes   \n",
       "2953   Mrs Todgers rises   Miss Pecksniffs rise allrise  \n",
       "2284  As  entered  city  mindswere filled   remembra...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>txt</th>\n      <th>final</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1122</th>\n      <td>\\n\\n“Let’s go on with the game,” the Queen sai...</td>\n      <td>Lets     game  Queen   Alice  Alice  toomuch f...</td>\n    </tr>\n    <tr>\n      <th>1222</th>\n      <td>But she was innocent.</td>\n      <td>But   innocent</td>\n    </tr>\n    <tr>\n      <th>3040</th>\n      <td>\\n\\n“Yes, to-day.”</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>2953</th>\n      <td>Mrs Todgers rises; the two Miss Pecksniffs ris...</td>\n      <td>Mrs Todgers rises   Miss Pecksniffs rise allrise</td>\n    </tr>\n    <tr>\n      <th>2284</th>\n      <td>As we entered this city, our minds\\nwere fille...</td>\n      <td>As  entered  city  mindswere filled   remembra...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "# import en dataset\n",
    "books = ['The Adventures of Sherlock Holmes.txt','Pride and Prejudice.txt','Life And Adventures Of Martin Chuzzlewit.txt','Frankenstein.txt','Alice’s Adventures in Wonderland.txt']\n",
    "# for i in range(36):\n",
    "#     books.append(\"en-art{:0>2}\".format(i))\n",
    "en_df = pd.DataFrame\n",
    "for book in books:\n",
    "    with open('./Data/en/'+book, encoding=\"utf8\") as f:\n",
    "        str_out = f.read()\n",
    "\n",
    "    nlp = English()\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "    tmp_df = pd.DataFrame([sent.text for sent in nlp(str_out).sents])\n",
    "    if en_df.empty:\n",
    "        en_df=tmp_df\n",
    "    else:\n",
    "        en_df = pd.concat([en_df,tmp_df],axis=0)\n",
    "en_df = en_df.sample(frac = 1)\n",
    "en_df = en_df[:SENTENCE_LIMIT]\n",
    "en_df.columns = ['txt']\n",
    "# stopwords and special characters\n",
    "en_df['final'] = en_df.apply(lambda x: pre_df(x['txt'],stopwords=en_stp),axis=1) \n",
    "en_df.dropna(inplace=True)\n",
    "en_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                      txt  \\\n",
       "252083  هشام حافظ (؛ ۲۸ آوریل ۱۹۳۱ – ۲۶ فوریه ۲۰۰۶) رو...   \n",
       "115414                ورزشگاه‌های کره جنوبی بر پایه استان   \n",
       "164360              دوربین‌های معرفی‌شده در ۲۰۱۰ (میلادی)   \n",
       "187655                      مناطق حفاظت شده سان‌فرانسیسکو   \n",
       "232758                  مسابقات بین‌المللی باشگاهی فوتبال   \n",
       "\n",
       "                                                    final  \n",
       "252083  هشام حافظ   آوریل    فوریه  روزنامه‌نگار اهل ع...  \n",
       "115414                  ورزشگاه‌های کره جنوبی  پایه استان  \n",
       "164360                         دوربین‌های معرفی‌   میلادی  \n",
       "187655                         مناطق حفاظت  سان‌فرانسیسکو  \n",
       "232758                  مسابقات بین‌المللی باشگاهی فوتبال  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>txt</th>\n      <th>final</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>252083</th>\n      <td>هشام حافظ (؛ ۲۸ آوریل ۱۹۳۱ – ۲۶ فوریه ۲۰۰۶) رو...</td>\n      <td>هشام حافظ   آوریل    فوریه  روزنامه‌نگار اهل ع...</td>\n    </tr>\n    <tr>\n      <th>115414</th>\n      <td>ورزشگاه‌های کره جنوبی بر پایه استان</td>\n      <td>ورزشگاه‌های کره جنوبی  پایه استان</td>\n    </tr>\n    <tr>\n      <th>164360</th>\n      <td>دوربین‌های معرفی‌شده در ۲۰۱۰ (میلادی)</td>\n      <td>دوربین‌های معرفی‌   میلادی</td>\n    </tr>\n    <tr>\n      <th>187655</th>\n      <td>مناطق حفاظت شده سان‌فرانسیسکو</td>\n      <td>مناطق حفاظت  سان‌فرانسیسکو</td>\n    </tr>\n    <tr>\n      <th>232758</th>\n      <td>مسابقات بین‌المللی باشگاهی فوتبال</td>\n      <td>مسابقات بین‌المللی باشگاهی فوتبال</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "# import fa dataset\n",
    "droped_columns = ['Id', 'Title', 'Type', 'Rank', 'Namespace', 'RedirectList',\n",
    "       'IsDisambiguationPage', 'TargetLinksCount', 'InfoBox', 'Links',\n",
    "       'Parents']\n",
    "fa_df = pd.read_json('./Data/fa/fawiki.json',lines=True)\n",
    "fa_df.drop(columns=droped_columns,inplace=True)\n",
    "fa_df = fa_df.sample(frac=1)\n",
    "fa_df = fa_df[:SENTENCE_LIMIT]\n",
    "fa_df.columns = ['txt']\n",
    "# stopwords and special characters\n",
    "fa_df['final'] = fa_df.apply(lambda x: pre_df(x['txt'],stopwords=fa_stp),axis=1) \n",
    "fa_df.dropna(inplace=True)\n",
    "fa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                      txt  \\\n",
       "9818    -- Det här berättar jag bara för dig , Clara ,...   \n",
       "75090   Det gick en del rykten om att potatisar kunde ...   \n",
       "104890                                              Nej !   \n",
       "58251   Då stördes hon inte av Mats hummanden och enst...   \n",
       "40106   Om kvinnorna glömmer sina män så ska vi män gl...   \n",
       "\n",
       "                                                    final  \n",
       "9818                Det  berättar      Clara  fortsatte    \n",
       "75090   Det    rykten   potatisar   giftiga    fel   g...  \n",
       "104890                                               Nej   \n",
       "58251   Då stördes    Mats hummanden  enstaka dunk  tr...  \n",
       "40106   Om kvinnorna glömmer  män    män glömma kvinno...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>txt</th>\n      <th>final</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9818</th>\n      <td>-- Det här berättar jag bara för dig , Clara ,...</td>\n      <td>Det  berättar      Clara  fortsatte</td>\n    </tr>\n    <tr>\n      <th>75090</th>\n      <td>Det gick en del rykten om att potatisar kunde ...</td>\n      <td>Det    rykten   potatisar   giftiga    fel   g...</td>\n    </tr>\n    <tr>\n      <th>104890</th>\n      <td>Nej !</td>\n      <td>Nej</td>\n    </tr>\n    <tr>\n      <th>58251</th>\n      <td>Då stördes hon inte av Mats hummanden och enst...</td>\n      <td>Då stördes    Mats hummanden  enstaka dunk  tr...</td>\n    </tr>\n    <tr>\n      <th>40106</th>\n      <td>Om kvinnorna glömmer sina män så ska vi män gl...</td>\n      <td>Om kvinnorna glömmer  män    män glömma kvinno...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "# import se dataset\n",
    "se_df = pd.read_csv('./Data/se/se-lite.txt', sep='\\n')\n",
    "se_df = se_df.sample(frac=1)\n",
    "se_df = se_df[:SENTENCE_LIMIT]\n",
    "se_df.columns = ['txt']\n",
    "# stopwords and special characters\n",
    "se_df['final'] = se_df.apply(lambda x: pre_df(x['txt'],stopwords=se_stp),axis=1) \n",
    "se_df.dropna(inplace=True)\n",
    "se_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['Unnamed: 0', 'text'], dtype='object')\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                      txt  \\\n",
       "236497  yaşındaki pilot muaz el kesasibe ışid in sana ...   \n",
       "89062   bu arada afp nin almanya merkezli recm karşıtl...   \n",
       "256585                                bibi nasıl başardı    \n",
       "199072  davutoğlu katar da ateşkes boyunca israil ve h...   \n",
       "50358           bu da kurtarılma ihtimallerini azaltıyor    \n",
       "\n",
       "                                                    final  \n",
       "236497  yaşındaki pilot muaz el kesasibe ışid in sana ...  \n",
       "89062    arada afp nin almanya merkezli recm karşıtlar...  \n",
       "256585                                bibi nasıl başardı   \n",
       "199072  davutoğlu katar  ateşkes boyunca israil  hamas...  \n",
       "50358                 kurtarılma ihtimallerini azaltıyor   "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>txt</th>\n      <th>final</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>236497</th>\n      <td>yaşındaki pilot muaz el kesasibe ışid in sana ...</td>\n      <td>yaşındaki pilot muaz el kesasibe ışid in sana ...</td>\n    </tr>\n    <tr>\n      <th>89062</th>\n      <td>bu arada afp nin almanya merkezli recm karşıtl...</td>\n      <td>arada afp nin almanya merkezli recm karşıtlar...</td>\n    </tr>\n    <tr>\n      <th>256585</th>\n      <td>bibi nasıl başardı</td>\n      <td>bibi nasıl başardı</td>\n    </tr>\n    <tr>\n      <th>199072</th>\n      <td>davutoğlu katar da ateşkes boyunca israil ve h...</td>\n      <td>davutoğlu katar  ateşkes boyunca israil  hamas...</td>\n    </tr>\n    <tr>\n      <th>50358</th>\n      <td>bu da kurtarılma ihtimallerini azaltıyor</td>\n      <td>kurtarılma ihtimallerini azaltıyor</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "# import tr dataset\n",
    "tr_df = pd.read_csv('./Data/tr/turkish.csv')\n",
    "tmp_df = pd.read_csv('./Data/tr/dunya-nz.txt',sep='\\n')\n",
    "\n",
    "tr_df = pd.concat([tr_df,tmp_df],axis=0)\n",
    "tr_df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "tr_df = tr_df.sample(frac=1)\n",
    "tr_df = tr_df[:SENTENCE_LIMIT]\n",
    "tr_df.columns = ['txt']\n",
    "# stopwords and special characters\n",
    "tr_df['final'] = tr_df.apply(lambda x: pre_df(x['txt'],stopwords=tr_stp),axis=1) \n",
    "tr_df.dropna(inplace=True)\n",
    "tr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}