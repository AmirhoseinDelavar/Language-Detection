{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit"
  },
  "interpreter": {
   "hash": "66c5ad3e4fe2006c058c4f7e9081f2a7de514f0ec125c3275fef48ae304ef2f7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE_LIMIT = 100000\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from spacy.lang.en import English\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stopwords\n",
    "gnr_stp = []\n",
    "with open('./Data/stopwords/gnr.txt', encoding=\"utf8\") as f:\n",
    "        for line in f.readlines():\n",
    "            gnr_stp.append(line.strip())\n",
    "\n",
    "ar_stp = pd.read_csv('./Data/stopwords/ar.txt',sep='\\n').values.reshape(-1)\n",
    "de_stp = pd.read_csv('./Data/stopwords/de.txt',sep='\\n').values.reshape(-1)\n",
    "en_stp = pd.read_csv('./Data/stopwords/en.txt',sep='\\n').values.reshape(-1)\n",
    "fa_stp = pd.read_csv('./Data/stopwords/fa.txt',sep='\\n').values.reshape(-1)\n",
    "se_stp = pd.read_csv('./Data/stopwords/se.txt',sep='\\n').values.reshape(-1)\n",
    "tr_stp = pd.read_csv('./Data/stopwords/tr.txt',sep='\\n').values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessor\n",
    "def pre_df(sentence,stopwords):\n",
    "    stopwords = stopwords.tolist()\n",
    "    sentence = str(sentence).replace('\\n','')\n",
    "    sentence = str(sentence).replace('\\t','')\n",
    "    sentence = str(sentence).replace('\\r','')\n",
    "    for sym in gnr_stp:\n",
    "        sentence = str(sentence).replace(sym,'')\n",
    "    for stp in stopwords:\n",
    "        sentence = re.sub(r'\\b'+str(stp)+r'\\b', '', str(sentence))\n",
    "    \n",
    "    return sentence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                     txt  \\\n",
       "37465  قالت الحكومة الإسبانية السبت إنه تم إطلاق سراح...   \n",
       "78751  أبرز لاعب وسط ريال مدريد البرازيلي كاسيميرو أن...   \n",
       "95502  احتضنت قاعة مندوبية الشباب والرياضة باكادير حف...   \n",
       "91688  ساعات في الجحيم بسبب اختناق المرور بعد مباراة ...   \n",
       "84752  حصدت بطولات الفئات الصغرى للعصبة في الموسم الم...   \n",
       "\n",
       "                                                   final  \n",
       "37465  قالت الحكومة الإسبانية السبت إنه  إطلاق سراح  ...  \n",
       "78751  أبرز لاعب وسط ريال مدريد البرازيلي كاسيميرو أن...  \n",
       "95502  احتضنت قاعة مندوبية الشباب والرياضة باكادير حف...  \n",
       "91688  ساعات  الجحيم  اختناق المرور  مباراة الأسود  ت...  \n",
       "84752  حصدت بطولات الفئات الصغرى للعصبة  الموسم  تشار...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>txt</th>\n      <th>final</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>37465</th>\n      <td>قالت الحكومة الإسبانية السبت إنه تم إطلاق سراح...</td>\n      <td>قالت الحكومة الإسبانية السبت إنه  إطلاق سراح  ...</td>\n    </tr>\n    <tr>\n      <th>78751</th>\n      <td>أبرز لاعب وسط ريال مدريد البرازيلي كاسيميرو أن...</td>\n      <td>أبرز لاعب وسط ريال مدريد البرازيلي كاسيميرو أن...</td>\n    </tr>\n    <tr>\n      <th>95502</th>\n      <td>احتضنت قاعة مندوبية الشباب والرياضة باكادير حف...</td>\n      <td>احتضنت قاعة مندوبية الشباب والرياضة باكادير حف...</td>\n    </tr>\n    <tr>\n      <th>91688</th>\n      <td>ساعات في الجحيم بسبب اختناق المرور بعد مباراة ...</td>\n      <td>ساعات  الجحيم  اختناق المرور  مباراة الأسود  ت...</td>\n    </tr>\n    <tr>\n      <th>84752</th>\n      <td>حصدت بطولات الفئات الصغرى للعصبة في الموسم الم...</td>\n      <td>حصدت بطولات الفئات الصغرى للعصبة  الموسم  تشار...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# import ar dataset\n",
    "ar_df = pd.read_csv('./Data/ar/ar.csv')\n",
    "ar_df = ar_df.sample(frac = 1)\n",
    "ar_df = ar_df[:SENTENCE_LIMIT]\n",
    "ar_df.drop(columns=['targe'],inplace=True)\n",
    "ar_df.columns = ['txt']\n",
    "ar_df.dropna(inplace=True)\n",
    "# stopwords and special characters\n",
    "ar_df['final'] = ar_df.apply(lambda x: pre_df(x['txt'],stopwords=ar_stp) ,axis=1)\n",
    "ar_df.dropna(inplace=True)\n",
    "ar_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                       txt  \\\n",
       "2065186  Schon gar nicht in der Ukraine, wo die Nachric...   \n",
       "1779085  Man muss sich mit Augenblicken zufrieden geben...   \n",
       "762206   Der Wagen gehört zum Fuhrpark der Bösen und ra...   \n",
       "547602   Dass Demmel ihn jedoch im Amt \"überfordert\" ne...   \n",
       "444795   Dann so wie Lotus in der F1 Also lediglich als...   \n",
       "\n",
       "                                                     final  \n",
       "2065186  Schon     Ukraine   Nachrichten fast täglich  ...  \n",
       "1779085  Man    Augenblicken zufrieden geben     heimis...  \n",
       "762206   Der Wagen gehört  Fuhrpark  Bösen  rast meist ...  \n",
       "547602   Dass Demmel    Amt überfordert nennt weist  en...  \n",
       "444795   Dann   Lotus   F Also lediglich  Sponsor     w...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>txt</th>\n      <th>final</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2065186</th>\n      <td>Schon gar nicht in der Ukraine, wo die Nachric...</td>\n      <td>Schon     Ukraine   Nachrichten fast täglich  ...</td>\n    </tr>\n    <tr>\n      <th>1779085</th>\n      <td>Man muss sich mit Augenblicken zufrieden geben...</td>\n      <td>Man    Augenblicken zufrieden geben     heimis...</td>\n    </tr>\n    <tr>\n      <th>762206</th>\n      <td>Der Wagen gehört zum Fuhrpark der Bösen und ra...</td>\n      <td>Der Wagen gehört  Fuhrpark  Bösen  rast meist ...</td>\n    </tr>\n    <tr>\n      <th>547602</th>\n      <td>Dass Demmel ihn jedoch im Amt \"überfordert\" ne...</td>\n      <td>Dass Demmel    Amt überfordert nennt weist  en...</td>\n    </tr>\n    <tr>\n      <th>444795</th>\n      <td>Dann so wie Lotus in der F1 Also lediglich als...</td>\n      <td>Dann   Lotus   F Also lediglich  Sponsor     w...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# import de dataset\n",
    "de_df = pd.read_csv('./Data/de/de.txt',sep='\\t')\n",
    "de_df = de_df.sample(frac = 1)\n",
    "de_df = de_df[:SENTENCE_LIMIT]\n",
    "de_df.drop(columns=[\"1\"],inplace=True)\n",
    "de_df.columns = ['txt']\n",
    "# stopwords and special characters\n",
    "de_df['final'] = de_df.apply(lambda x: pre_df(x['txt'],stopwords=de_stp),axis=1) \n",
    "de_df.dropna(inplace=True)\n",
    "de_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                    txt  \\\n",
       "928                   Always lay the\\nblame on others!”   \n",
       "154   \\nShe was the most arch and at the same time t...   \n",
       "3974         I say, young ladies, I’m a-going to leave.   \n",
       "3443                               said Mr Pecksniff. ‘   \n",
       "3535  Mr\\nJinkins is hard upon him sometimes, but no...   \n",
       "\n",
       "                                                  final  \n",
       "928                               Always lay theblame    \n",
       "154   She    arch     time   artless creaturewas   M...  \n",
       "3974                        I   ladies Im agoing  leave  \n",
       "3443                                      Mr Pecksniff   \n",
       "3535             MrJinkins  hard        hard   deserves  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>txt</th>\n      <th>final</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>928</th>\n      <td>Always lay the\\nblame on others!”</td>\n      <td>Always lay theblame</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>\\nShe was the most arch and at the same time t...</td>\n      <td>She    arch     time   artless creaturewas   M...</td>\n    </tr>\n    <tr>\n      <th>3974</th>\n      <td>I say, young ladies, I’m a-going to leave.</td>\n      <td>I   ladies Im agoing  leave</td>\n    </tr>\n    <tr>\n      <th>3443</th>\n      <td>said Mr Pecksniff. ‘</td>\n      <td>Mr Pecksniff</td>\n    </tr>\n    <tr>\n      <th>3535</th>\n      <td>Mr\\nJinkins is hard upon him sometimes, but no...</td>\n      <td>MrJinkins  hard        hard   deserves</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# import en dataset\n",
    "books = ['The Adventures of Sherlock Holmes.txt','Pride and Prejudice.txt','Life And Adventures Of Martin Chuzzlewit.txt','Frankenstein.txt','Alice’s Adventures in Wonderland.txt']\n",
    "# for i in range(36):\n",
    "#     books.append(\"en-art{:0>2}\".format(i))\n",
    "en_df = pd.DataFrame\n",
    "for book in books:\n",
    "    with open('./Data/en/'+book, encoding=\"utf8\") as f:\n",
    "        str_out = f.read()\n",
    "\n",
    "    nlp = English()\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "    tmp_df = pd.DataFrame([sent.text for sent in nlp(str_out).sents])\n",
    "    if en_df.empty:\n",
    "        en_df=tmp_df\n",
    "    else:\n",
    "        en_df = pd.concat([en_df,tmp_df],axis=0)\n",
    "en_df = en_df.sample(frac = 1)\n",
    "en_df = en_df[:SENTENCE_LIMIT]\n",
    "en_df.columns = ['txt']\n",
    "# stopwords and special characters\n",
    "en_df['final'] = en_df.apply(lambda x: pre_df(x['txt'],stopwords=en_stp),axis=1) \n",
    "en_df.dropna(inplace=True)\n",
    "en_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                      txt  \\\n",
       "188472  سان را (; – ) آهنگساز، تنظیم‌کننده، پیانیست و ...   \n",
       "198736              مهره‌داران توصیف‌شده در ۱۹۵۵ (میلادی)   \n",
       "265149                          تانزانیا در ۱۹۷۴ (میلادی)   \n",
       "198754              مهره‌داران توصیف‌شده در ۱۹۷۹ (میلادی)   \n",
       "107518                    گروه‌های موسیقی اوماها، نبراسکا   \n",
       "\n",
       "                                                    final  \n",
       "188472  سان     آهنگساز تنظیم‌کننده پیانیست و کیبوردنو...  \n",
       "198736                         مهره‌داران توصیف‌   میلادی  \n",
       "265149                                  تانزانیا   میلادی  \n",
       "198754                         مهره‌داران توصیف‌   میلادی  \n",
       "107518                     گروه‌های موسیقی اوماها نبراسکا  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>txt</th>\n      <th>final</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>188472</th>\n      <td>سان را (; – ) آهنگساز، تنظیم‌کننده، پیانیست و ...</td>\n      <td>سان     آهنگساز تنظیم‌کننده پیانیست و کیبوردنو...</td>\n    </tr>\n    <tr>\n      <th>198736</th>\n      <td>مهره‌داران توصیف‌شده در ۱۹۵۵ (میلادی)</td>\n      <td>مهره‌داران توصیف‌   میلادی</td>\n    </tr>\n    <tr>\n      <th>265149</th>\n      <td>تانزانیا در ۱۹۷۴ (میلادی)</td>\n      <td>تانزانیا   میلادی</td>\n    </tr>\n    <tr>\n      <th>198754</th>\n      <td>مهره‌داران توصیف‌شده در ۱۹۷۹ (میلادی)</td>\n      <td>مهره‌داران توصیف‌   میلادی</td>\n    </tr>\n    <tr>\n      <th>107518</th>\n      <td>گروه‌های موسیقی اوماها، نبراسکا</td>\n      <td>گروه‌های موسیقی اوماها نبراسکا</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# import fa dataset\n",
    "droped_columns = ['Id', 'Title', 'Type', 'Rank', 'Namespace', 'RedirectList',\n",
    "       'IsDisambiguationPage', 'TargetLinksCount', 'InfoBox', 'Links',\n",
    "       'Parents']\n",
    "fa_df = pd.read_json('./Data/fa/fawiki.json',lines=True)\n",
    "fa_df.drop(columns=droped_columns,inplace=True)\n",
    "fa_df = fa_df.sample(frac=1)\n",
    "fa_df = fa_df[:SENTENCE_LIMIT]\n",
    "fa_df.columns = ['txt']\n",
    "# stopwords and special characters\n",
    "fa_df['final'] = fa_df.apply(lambda x: pre_df(x['txt'],stopwords=fa_stp),axis=1) \n",
    "fa_df.dropna(inplace=True)\n",
    "fa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                      txt  \\\n",
       "86820   Jag sa att vi är två , men menar naturligtvis ...   \n",
       "55739   Nu får han ligga på sofflocket och ta det så v...   \n",
       "9982          Kanske skulle Mats rentav uppskatta gåvan ?   \n",
       "132045                                 Sen tog Tina vid :   \n",
       "38046   Strax nedanför höftbenet hade ett första liggs...   \n",
       "\n",
       "                                                    final  \n",
       "86820   Jag sa   är    menar naturligtvis  JAG är     ...  \n",
       "55739                    Nu     sofflocket  ta   varligt   \n",
       "9982                 Kanske  Mats rentav uppskatta gåvan   \n",
       "132045                                     Sen tog Tina    \n",
       "38046   Strax nedanför höftbenet    liggsår öppnat  gl...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>txt</th>\n      <th>final</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>86820</th>\n      <td>Jag sa att vi är två , men menar naturligtvis ...</td>\n      <td>Jag sa   är    menar naturligtvis  JAG är     ...</td>\n    </tr>\n    <tr>\n      <th>55739</th>\n      <td>Nu får han ligga på sofflocket och ta det så v...</td>\n      <td>Nu     sofflocket  ta   varligt</td>\n    </tr>\n    <tr>\n      <th>9982</th>\n      <td>Kanske skulle Mats rentav uppskatta gåvan ?</td>\n      <td>Kanske  Mats rentav uppskatta gåvan</td>\n    </tr>\n    <tr>\n      <th>132045</th>\n      <td>Sen tog Tina vid :</td>\n      <td>Sen tog Tina</td>\n    </tr>\n    <tr>\n      <th>38046</th>\n      <td>Strax nedanför höftbenet hade ett första liggs...</td>\n      <td>Strax nedanför höftbenet    liggsår öppnat  gl...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# import se dataset\n",
    "se_df = pd.read_csv('./Data/se/se-lite.txt', sep='\\n')\n",
    "se_df = se_df.sample(frac=1)\n",
    "se_df = se_df[:SENTENCE_LIMIT]\n",
    "se_df.columns = ['txt']\n",
    "# stopwords and special characters\n",
    "se_df['final'] = se_df.apply(lambda x: pre_df(x['txt'],stopwords=se_stp),axis=1) \n",
    "se_df.dropna(inplace=True)\n",
    "se_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                      txt  \\\n",
       "77085   rivlin ™in iddiasına göre baskı sonuç verdi ve...   \n",
       "321991  yunan başbakanı na türkiye ziyaretini sığınmac...   \n",
       "68393                 artık son karar parti kurullarında    \n",
       "197092  çavuşoğlu dışişleri bakanı klimkin ile görüşme...   \n",
       "282203  bu karara itiraz eden kuzen rami makhlouf bir ...   \n",
       "\n",
       "                                                    final  \n",
       "77085   rivlin ™in iddiasına göre baskı sonuç verdi  a...  \n",
       "321991  yunan başbakanı na türkiye ziyaretini sığınmac...  \n",
       "68393                 artık son karar parti kurullarında   \n",
       "197092  çavuşoğlu dışişleri bakanı klimkin  görüşmesin...  \n",
       "282203   karara itiraz eden kuzen rami makhlouf  üst m...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>txt</th>\n      <th>final</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>77085</th>\n      <td>rivlin ™in iddiasına göre baskı sonuç verdi ve...</td>\n      <td>rivlin ™in iddiasına göre baskı sonuç verdi  a...</td>\n    </tr>\n    <tr>\n      <th>321991</th>\n      <td>yunan başbakanı na türkiye ziyaretini sığınmac...</td>\n      <td>yunan başbakanı na türkiye ziyaretini sığınmac...</td>\n    </tr>\n    <tr>\n      <th>68393</th>\n      <td>artık son karar parti kurullarında</td>\n      <td>artık son karar parti kurullarında</td>\n    </tr>\n    <tr>\n      <th>197092</th>\n      <td>çavuşoğlu dışişleri bakanı klimkin ile görüşme...</td>\n      <td>çavuşoğlu dışişleri bakanı klimkin  görüşmesin...</td>\n    </tr>\n    <tr>\n      <th>282203</th>\n      <td>bu karara itiraz eden kuzen rami makhlouf bir ...</td>\n      <td>karara itiraz eden kuzen rami makhlouf  üst m...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# import tr dataset\n",
    "tr_df = pd.read_csv('./Data/tr/turkish.csv')\n",
    "tmp_df = pd.read_csv('./Data/tr/dunya-nz.txt',sep='\\n')\n",
    "\n",
    "tr_df = pd.concat([tr_df,tmp_df],axis=0)\n",
    "tr_df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "tr_df = tr_df.sample(frac=1)\n",
    "tr_df = tr_df[:SENTENCE_LIMIT]\n",
    "tr_df.columns = ['txt']\n",
    "# stopwords and special characters\n",
    "tr_df['final'] = tr_df.apply(lambda x: pre_df(x['txt'],stopwords=tr_stp),axis=1) \n",
    "tr_df.dropna(inplace=True)\n",
    "tr_df.head()"
   ]
  },
  {
   "source": [
    "# Feature Extraction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling\n",
    "ar_df['label'] = 'ar'\n",
    "de_df['label'] = 'de'\n",
    "en_df['label'] = 'en'\n",
    "fa_df['label'] = 'fa'\n",
    "se_df['label'] = 'se'\n",
    "tr_df['label'] = 'tr'\n",
    "# cleaning\n",
    "ar_df.drop(columns=['txt'],inplace=True)\n",
    "de_df.drop(columns=['txt'],inplace=True)\n",
    "en_df.drop(columns=['txt'],inplace=True)\n",
    "fa_df.drop(columns=['txt'],inplace=True)\n",
    "se_df.drop(columns=['txt'],inplace=True)\n",
    "tr_df.drop(columns=['txt'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                    final label\n",
       "221926  son gelişmelerle ilgili olarak  yazık   ciddi ...    tr\n",
       "51040   araştırmalardan birine göre çocukluk fotoğrafl...    tr\n",
       "102349  tamaulipas eyaleti uyuşturucu kaçakçılığına ba...    tr\n",
       "49610   sendika başkanı christophe regnard tarafsız ha...    tr\n",
       "208126  cunta lideri prayut un iddialarına ülke geneli...    tr"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>final</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>221926</th>\n      <td>son gelişmelerle ilgili olarak  yazık   ciddi ...</td>\n      <td>tr</td>\n    </tr>\n    <tr>\n      <th>51040</th>\n      <td>araştırmalardan birine göre çocukluk fotoğrafl...</td>\n      <td>tr</td>\n    </tr>\n    <tr>\n      <th>102349</th>\n      <td>tamaulipas eyaleti uyuşturucu kaçakçılığına ba...</td>\n      <td>tr</td>\n    </tr>\n    <tr>\n      <th>49610</th>\n      <td>sendika başkanı christophe regnard tarafsız ha...</td>\n      <td>tr</td>\n    </tr>\n    <tr>\n      <th>208126</th>\n      <td>cunta lideri prayut un iddialarına ülke geneli...</td>\n      <td>tr</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# concat\n",
    "df = pd.concat([ar_df,de_df,en_df,fa_df,se_df,tr_df],axis=0)\n",
    "df.to_csv('pr_100k_data.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pr_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['final'].to_numpy(), df.label.to_numpy(), test_size=0.33, random_state=404)\n",
    "# vectorize by 2 characters\n",
    "cnt = CountVectorizer(analyzer = 'char',ngram_range=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training Naive Bayes\n",
    "pipeline = Pipeline([\n",
    "   ('vectorizer',cnt),  \n",
    "   ('model',MultinomialNB())\n",
    "])\n",
    "pipeline.fit(X_train,y_train)\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training Linear Classifier\n",
    "pipeline = Pipeline([\n",
    "   ('vectorizer',cnt),  \n",
    "   ('model',LogisticRegression(max_iter=500))\n",
    "])\n",
    "pipeline.fit(X_train,y_train)\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training Support Vector\n",
    "pipeline = Pipeline([\n",
    "   ('vectorizer',cnt),\n",
    "   ('standardscaler', StandardScaler(with_mean=False)),  \n",
    "   ('model',SVC())\n",
    "])\n",
    "pipeline.fit(X_train,y_train)\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[32062     0     2     3     0     0]\n",
      " [    0 32792   135     0    83    11]\n",
      " [    0   161  6768    61    82    83]\n",
      " [   25    15    45 32915    11     0]\n",
      " [    0   640   226   249 31842   105]\n",
      " [    0    53   128    14    29 32788]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ar       1.00      1.00      1.00     32067\n",
      "          de       0.97      0.99      0.98     33021\n",
      "          en       0.93      0.95      0.94      7155\n",
      "          fa       0.99      1.00      0.99     33011\n",
      "          se       0.99      0.96      0.98     33062\n",
      "          tr       0.99      0.99      0.99     33012\n",
      "\n",
      "    accuracy                           0.99    171328\n",
      "   macro avg       0.98      0.98      0.98    171328\n",
      "weighted avg       0.99      0.99      0.99    171328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# results\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['fa']\n['en']\n['de']\n['ar']\n['tr']\n['se']\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print(pipeline.predict(['سلام بر شما دوست عزیز']))\n",
    "print(pipeline.predict(['to night we will rock the hell out of the place']))\n",
    "print(pipeline.predict(['Heute Nacht werden wir die Hölle auf dem Platz rocken']))\n",
    "print(pipeline.predict(['إلى الليل سنهزّ الجحيم في المكان']))\n",
    "print(pipeline.predict(['geceye cehennemi oralarda sallayacağız']))\n",
    "print(pipeline.predict(['i natt kommer vi att rocka helvetet på platsen']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}